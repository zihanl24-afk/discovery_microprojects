{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h1 style=\"text-align: center\">\n",
    "<div style=\"color: #DD3403; font-size: 60%\">Data Science DISCOVERY MicroProject</div>\n",
    "<span style=\"\">MicroProject #3: Highest Mountains in the World</span>\n",
    "<div style=\"font-size: 60%;\"><a href=\"https://discovery.cs.illinois.edu/microproject/highest-mountain/\">https://discovery.cs.illinois.edu/microproject/highest-mountain/</a></div>\n",
    "</h1>\n",
    "\n",
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Source: Wikipedia's \"List of mountains by elevation\"\n",
    "\n",
    "Wikipedia is an ad-free, open source, and very reliable source of information about almost every topic you can imagine!  In this MicroProject, you will explore how to easily import data from any Wikipedia tables into a DataFrame.\n",
    "\n",
    "The Wikipedia article \"List of mountains by elevation\" (https://en.wikipedia.org/wiki/List_of_mountains_by_elevation) contains information on hundreds of mountains -- including **Mount Everest** (tallest in the world), **Denali / Mount McKinley** (tallest in the United States), and hundreds more!\n",
    "- Click the Wikipedia link above to view how the Wikipedia page looks in your web browser before we begin to work with it in Python!\n",
    "\n",
    "Once you've taken a look at the data, let's nerd out with gathering data from Wikipedia!\n",
    "\n",
    "### Background Knowledge\n",
    "\n",
    "To finish this MicroProject, we assume you already know how to:\n",
    "\n",
    "- Load a CSV file into a DataFrame using `pd.read_csv` ([review loading a CSV file](https://discovery.cs.illinois.edu/learn/Basics-of-Data-Science-with-Python/Python-for-Data-Science-Introduction-to-DataFrames/)),\n",
    "- Perform simple row selection of a DataFrame ([review row selection](https://discovery.cs.illinois.edu/learn/Basics-of-Data-Science-with-Python/Row-Selection-with-DataFrames/)), and\n",
    "- Work with using conditionals row selection of a DataFrame ([review conditionals with DataFrames](https://discovery.cs.illinois.edu/learn/Basics-of-Data-Science-with-Python/DataFrames-with-Conditionals/))\n",
    "\n",
    "With that knowledge, this MicroProject will guide you through nerding out with gathering data from Wikipedia and finding some facts about the tallest mountains in the world.  Let's get started! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 1: Fetching Data From Wikipedia\n",
    "\n",
    "The Wikipedia article \"List of mountains by elevation\" is organized into several tables of data:\n",
    "\n",
    "- One table for mountains that are at least 8,000m in height,\n",
    "- Another table for 7,000m mountains  (7,000m - 7,999m),\n",
    "- Another table for 6,000m mountains  (6,000m - 6,999m),\n",
    "- ...and so on...\n",
    "\n",
    "The `pd.read_html(...)` function in the pandas library is designed to **read data from tables found in webpages**.\n",
    "\n",
    "### Part 1.1: Using `pd.read_html`\n",
    "\n",
    "In the following cell, we'll use `pd.read_html(...)` to read all of the tables from the Wikipedia page  \"List of mountains by elevation\" (https://en.wikipedia.org/wiki/List_of_mountains_by_elevation).  Here's a brief overview of the `pd.read_html` function:\n",
    "\n",
    "- The `read_html` function is **very similar** to the commonly used `read_csv`.\n",
    "- Instead of returning a DataFrame from a CSV file, the `read_html` returns **one DataFrame for each table on the website** as a Python list of DataFrames.  *(For our Wikipedia page, this means we'll have 8 different DataFrames since there are eight different tables.*)\n",
    "- Just like `read_csv`, you only need to provide the URL of the data! ðŸŽ‰\n",
    "\n",
    "Fetch a list of DataFrames, where each DataFrame is a table from the Wikipedia page \"List of mountains by elevation\" store it in the Python variable `dfList`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch a list of DataFrames, where each DataFrame is a table from the Wikipedia page\n",
    "# \"List of mountains by elevation\" store it in the Python variable `dfList`:\n",
    "# - The page's URL is: https://en.wikipedia.org/wiki/List_of_mountains_by_elevation\n",
    "dfList = ...\n",
    "dfList"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ðŸ”¬ Checkpoint Tests ðŸ”¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 1.1: Using pd.read_html\n",
    "#\n",
    "# What is this cell?\n",
    "# - This cell contains test cases for the MicroProject.  You can modify anything except\n",
    "#   the first line of this cell, but we will replace this cell with a new version of this\n",
    "#   cell when your MicroProject is graded.  It's usually best to not change this cell!\n",
    "#\n",
    "# - To run the test cases we have for you, just run this Python cell like any other cell! :)\n",
    "#\n",
    "# - If this cell runs without any error in the output, you PASSED all test cases!\n",
    "#   We try and make these test cases as useful and complete as possible, but there is\n",
    "#   a chance your code may be incorrect even though you pass the test cases (these\n",
    "#   tests should be seen as a way to give you confidence that code you understand how\n",
    "#   it works is actually correct, not as a robust check to catch all possible errors).\n",
    "#\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and\n",
    "#   RE-RUN your code and then re-run this cell.  Keep repeating this until the cell\n",
    "#   passed with no errors! :)\n",
    "#\n",
    "# - You will find more cells that begin with the words \"TEST CASE\" throughout the\n",
    "#   notebook at important points to make sure everything is looking good so far!\n",
    "#\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"dfList\" in vars()), \"You must define a Python variable called `dfList`.\"\n",
    "assert(type(dfList) == type([])), \"Your Python variable `dfList` must contain a list.\"\n",
    "assert(type(dfList[0]) == type(pd.DataFrame())), \"Your Python variable `dfList` must contain a list of DataFrames.\"\n",
    "assert(\"Feet\" in dfList[0]), \"Your Python variable `dfList` must be from the Wikipedia page 'List of mountains by elevation'.\"\n",
    "assert(\"Range\" in dfList[1]), \"Your Python variable `dfList` must be from the Wikipedia page 'List of mountains by elevation'.\"\n",
    "assert(\"Mountain\" in dfList[2]), \"Your Python variable `dfList` must be from the Wikipedia page 'List of mountains by elevation'.\"\n",
    "assert(\"Location and Notes\" in dfList[3]), \"Your Python variable `dfList` must be from the Wikipedia page 'List of mountains by elevation'.\"\n",
    "assert(\"Metres\" in dfList[4]), \"Your Python variable `dfList` must be from the Wikipedia page 'List of mountains by elevation'.\"\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 1.2: Exploring the List of DataFrames\n",
    "\n",
    "Your variable `dfList` contains a **Python `list`** of several DataFrames, one DataFrame for each table on the webpage.  To use this as one complete dataset, we need to join the lists together into one large DataFrame.\n",
    "\n",
    "Before we do that, let's explore the individual DataFrames.  To look at the first item a `list`, we access the `0th` index of the list by using the Python code:\n",
    "\n",
    "> ```py\n",
    "> # Accesses the first element (index 0) of a list called `myList`\n",
    "> myList[0]\n",
    "> ```\n",
    "\n",
    "Applying this to the variable `dfList`, the following code displays the first DataFrame stored in `dfList`.  This first DataFrame contains the data from the first table on the Wikipedia page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "The second DataFrame is accessed at index `[1]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Continue to look at each index, until you find the **very last DataFrame** in the list that contains data about the mountains.  *(We'll need to know the last index for the next section.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the very last DataFrame containing data about the mountains from Wikipedia:\n",
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 1.3: Joining the individual DataFrames into one large DataFrame\n",
    "\n",
    "Before we can do analysis on the whole dataset, we need to join the individual DataFrames together into one large DataFrame.  When we join DataFrames end-to-end, where the last row of the previous DataFrame is followed by the first row of the next DataFrame, the operation is called **concatenation**.\n",
    "\n",
    "Read the DISCOVERY guide to learn the syntax on \"Combining DataFrames by Concatenation\"\n",
    "- [DISCOVERY Guide: \"Combining DataFrames by Concatenation\"](https://discovery.cs.illinois.edu/guides/Combining-DataFrames/Combining-DataFrames-by-Concatenation/)\n",
    "- https://discovery.cs.illinois.edu/guides/Combining-DataFrames/Combining-DataFrames-by-Concatenation/\n",
    "\n",
    "Use concatenation to create a single DataFrame `df` that contains data about every mountain found on the Wikipedia page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ...\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ðŸ”¬ Checkpoint Tests ðŸ”¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 1.3: Joining the individual DataFrames into one large DataFrame\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"df\" in vars()), \"You must create a variable called `df` that is a single DataFrame (not a list).\"\n",
    "assert(type(dfList) == type([])), \"You must NOT override `dfList`.  The variable `dfList` must still be a DataFrame for each table on Wikipedia.\"\n",
    "assert(len(df) > len(dfList[0])), \"You must concat all of the DataFrames together into one large DataFrame `df`.\"\n",
    "assert(\"Feet\" in df), \"Your DataFrame stored in the variable `df` must be a concatenation of all the individual DataFrames in `dfList`.\"\n",
    "assert(\"Mountain\" in df), \"Your DataFrame stored in the variable `df` must be a concatenation of all the individual DataFrames in `dfList`.\"\n",
    "assert(\"Hindu Kush\" in df[\"Range\"].values), \"Your DataFrame stored in the variable `df` must be a concatenation of all the individual DataFrames in `dfList`.  (You are missing at least one table.)\"\n",
    "assert(\"K2\" in df[\"Mountain\"].values), \"Your DataFrame stored in the variable `df` must be a concatenation of all the individual DataFrames in `dfList`.  (You are missing at least one table.)\"\n",
    "assert(\"Batura Sar\" in df[\"Mountain\"].values), \"Your DataFrame stored in the variable `df` must be a concatenation of all the individual DataFrames in `dfList`.  (You are missing at least one table.)\"\n",
    "assert(\"Meru Peak\" in df[\"Mountain\"].values), \"Your DataFrame stored in the variable `df` must be a concatenation of all the individual DataFrames in `dfList`.  (You are missing at least one table.)\"\n",
    "assert(\"Ubinas\" in df[\"Mountain\"].values), \"Your DataFrame stored in the variable `df` must be a concatenation of all the individual DataFrames in `dfList`.  (You are missing at least one table.)\"\n",
    "assert(len(df) > 1500 and len(df) < 1650), \"Your DataFrame stored in the variable `df` must be a concatenation of all the individual DataFrames in `dfList`.  (You are missing at least one table.)\"\n",
    "assert(len(df[ df[\"Location and Notes\"].str.contains(\"Himalayas\")]) == 35), \"Your DataFrame stored in the variable `df` must be a concatenation of all the individual DataFrames in `dfList`.  (You are missing at least one table.)\"\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2: Mountains in the United States\n",
    "\n",
    "Now that we have every mountain in a single DataFrame, we can do some analysis!\n",
    "\n",
    "In the dataset, the `Location and Notes` column contains a human-written description of the location and other notes.  For example, the notes about the mountain \"Makalu\" notes that the mountain is in \"Nepal\".\n",
    "\n",
    "To do the next analysis, we want to select from all the mountains in the entire dataset `df` and find only the mountains located in the United States.\n",
    "\n",
    "To do this, you'll need to do two things:\n",
    "\n",
    "1. First, look back at the [Wikipedia page](https://en.wikipedia.org/wiki/List_of_mountains_by_elevation), or explore `df` here in Python, to find out **all the different ways mountains in the United States might be labeled**.  *(Hint: There's two different ways!)*\n",
    "2. Second, read the DISCOVERY guide to learn the syntax on \"Selecting DataFrame Rows Based on String Contents\" to identify how we can use the two different ways the United States is labeled:\n",
    "    - [DISCOVERY Guide: \"Selecting DataFrame Rows Based on String Contents\"](https://discovery.cs.illinois.edu/guides/DataFrame-Row-Selection/dataframe-string-contains/)\n",
    "    - https://discovery.cs.illinois.edu/guides/DataFrame-Row-Selection/dataframe-string-contains/\n",
    "\n",
    "Create a DataFrame of only the mountains in the United States and store it in the variable `df_us` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of only the mountains in the United States and store it in the variable `df_us`:\n",
    "df_us = ...\n",
    "df_us"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 2 Analysis: Percentage of Mountains in the Dataset in the United States?\n",
    "\n",
    "What percentage of mountains in the entire dataset are found in the United States?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_us = ...\n",
    "pct_us"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ðŸ”¬ Checkpoint Tests ðŸ”¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 2: Mountains in the United States\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"df_us\" in vars()), \"You must create a variable called `df_us`.\"\n",
    "assert(len(df_us) > 300 and len(df_us) < 400), \"You DataFrame must contain ALL mountains in the United States. It appears you have not identified the two different ways that the United States appears in the Wikipedia tables.\"\n",
    "assert(len(df_us[ df_us.Mountain.str.contains(\"Mount Saint Elias\")]) == 1), \"You DataFrame must contain ALL mountains in the United States. It appears you have not identified the two different ways that the United States appears in the Wikipedia tables.\"\n",
    "assert(len(df_us[ df_us.Mountain.str.contains(\"Denali\")]) == 1), \"You DataFrame must contain ALL mountains in the United States. It appears you have not identified the two different ways that the United States appears in the Wikipedia tables.\"\n",
    "assert(\"Ubinas\" not in df_us[\"Mountain\"]), \"You DataFrame must contain ALL mountains in the United States. It appears you have not identified the two different ways that the United States appears in the Wikipedia tables.\"\n",
    "assert(\"Carihuairazo\" not in df_us[\"Mountain\"]), \"You DataFrame must contain ALL mountains in the United States. It appears you have not identified the two different ways that the United States appears in the Wikipedia tables.\"\n",
    "assert(\"Sirbal Peak\" not in df_us[\"Mountain\"]), \"You DataFrame must contain ALL mountains in the United States. It appears you have not identified the two different ways that the United States appears in the Wikipedia tables.\"\n",
    "\n",
    "assert(\"pct_us\" in vars()), \"You must create a variable called `pct_us`.\"\n",
    "assert(pct_us > 0 and pct_us < 1), \"The variable called `pct_us` must contain a percentage between 0 and 1.\"\n",
    "assert(pct_us == len(df_us) / len(df)), \"The variable called `pct_us` must contain the percentage of mountains in the United States among all the mountains in the dataset.\"\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 3: Higher than the Highest Mountain in the United States\n",
    "\n",
    "You have identified the highest mountains in the United States, and also have the data for the highest mountains across the world! ðŸŽ‰\n",
    "\n",
    "In the final puzzle for this MicroProject, create a DataFrame that contains **ALL** of the mountains that have a height that is higher than the highest mountain in the United States.  Store the DataFrame in the Python variable `df_higherThanUS`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store your new DataFrame in the variable `df_higherThanUS`:\n",
    "df_higherThanUS = ...\n",
    "df_higherThanUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.reset_index()\n",
    "x[x[\"Location and Notes\"].str.contains(\"US\") | x[\"Location and Notes\"].str.contains(\"United States\") ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 3 Visualization: Heights of Various Mountains\n",
    "\n",
    "A bar chart is a great way to visualize data that contains non-numeric data or categories.  In this MicroProject, you have explored the height of various mountains -- let's visualize just how tall Mount Everest compared to other mountains in this dataset.\n",
    "\n",
    "Since there are over 1,000 mountains in the dataset, our visualization will show a subset of all the mountains.  Specifically, we'll visualize **ever 61st mountain** -- indexes `[0]`, `[61]`, `[122]`, `[183]`, `[244]`, etc.\n",
    "\n",
    "Selecting only every 61st mountain can be done by selecting a range from your DataFrame with the following format:\n",
    "> ```py\n",
    "> # Selects every 61st row, starting with [0]:\n",
    "> df[::61]\n",
    "> ```\n",
    "\n",
    "Creating a bar chart from a DataFrame is done by using the general format:\n",
    "\n",
    "> ```py\n",
    "> # Generic format for a bar chart from a DataFrame:\n",
    "> df.plot.bar(x=\"data-column-name\", y=\"data-column-name\")\n",
    "> ```\n",
    "\n",
    "Combining these together, your bar chart can be created with the general format:\n",
    "\n",
    "> ```py\n",
    "> # Generic format for a bar chart of every 61st row of a DataFrame:\n",
    "> df[::61].plot.bar(x=\"data-column-name\", y=\"data-column-name\")\n",
    "> ```\n",
    "\n",
    "#### Create Your Visualization\n",
    "\n",
    "Create a bar chart below, using the mountain name for your `x`-axis data and the height (either feet or meters, your choice!) for the `y`-axis data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart\n",
    "# - using the mountain name for your `x`-axis data, and\n",
    "# - using the height (either feet or meters, your choice!) for the `y`-axis data\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ðŸ”¬ Checkpoint Tests ðŸ”¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 3: Higher than the Highest Mountain in the United States\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"df_higherThanUS\" in vars()), \"You must create a variable called `df_higherThanUS`.\"\n",
    "assert( len(list(set(df_higherThanUS[\"Mountain\"]) & set(df_us[\"Mountain\"]))) == 0 ), \"Some of the mountains in `df_higherThanUS` are in the United States, but there should be none.\"\n",
    "assert( len(df_higherThanUS) == len(df[ df.Feet > df_us.sort_values(\"Feet\", ascending=False).iloc[0].Feet ]) ), \"There are some mountains in `df_higherThanUS` that are shorter than the highest mountain in the United States, but there should be none.\"\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submission\n",
    "\n",
    "You're almost done!  All you need to do is to commit your lab to GitHub and run the GitHub Actions Grader:\n",
    "\n",
    "1.  âš ï¸ **Make certain to save your work.** âš ï¸ To do this, go to **File => Save All**\n",
    "\n",
    "2.  After you have saved, exit this notebook and return to https://discovery.cs.illinois.edu/microproject/highest-mountain/ and complete the section **\"Commit and Grade Your Notebook\"**.\n",
    "\n",
    "3. If you see a 100% grade result on your GitHub Action, you've completed this MicroProject! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
